Attacking machine learning algorithms by using pertubations of the inputs. Boundary Attack: Attack algorithm is initialized at a point that is already adversarial. Performing a random walk along the boundary between adversarial and non-adversarial area. This is done in such a way that the algorithm remains in the adversarial area and the distance to the target image becomes smaller.  Thus, one tries to find smaller adversarial pertubations based on an adversarial criterion ( e.g. misclassification).  Two relevant parameters: Length of total pertubation and distance to original input. Boundary Attack is immune to defenses based on gradient-masking. Boundary Attack has been successfully used in real world image recognition applications. The adversarial examples, which were created by the Boundary Attack, had such small pertubations, that a differentiation from the original was hardly possible and still wrongly classified.
